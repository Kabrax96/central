# central
Automatizar informaciÃ³n de consejo Nuevo LeÃ³n



# ğŸ“Š Presupuesto Data ETL Pipeline

## ğŸ† **Project Overview**
This ETL (Extract, Transform, Load) pipeline automates the process of extracting presupuesto data from multiple **CSV** and **Excel** files, transforming it into a structured format, and loading it into a **PostgreSQL** database. The pipeline handles both individual and bulk file processing while maintaining detailed logs for auditing and troubleshooting.

---

## ğŸ“ **Project Structure**

```
app/
â”‚
â”œâ”€â”€ etl_project/                      # Main ETL project directory
â”‚   â”‚
â”‚   â”œâ”€â”€ assets/                        # Core ETL utilities and helper scripts
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ metadata_logging.py        # Metadata logging functions
â”‚   â”‚   â”œâ”€â”€ pipeline_logging.py        # Logging utility (Loguru-based)
â”‚   â”‚   â”œâ”€â”€ presupuesto_etl.py         # Extract, Transform, Load (ETL) functions
â”‚   â”‚
â”‚   â”œâ”€â”€ connectors/                    # Database connectors
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ postgresql.py               # PostgreSQL client connector
â”‚   â”‚
â”‚   â”œâ”€â”€ data/                          # Data storage
â”‚   â”‚   â”œâ”€â”€ presupuestos/              # Financial data files (CSV/Excel)
â”‚   â”‚   â”‚   â”œâ”€â”€ Nuevo_Leon_Financials_2024_Q1_daily.csv
â”‚   â”‚   â”‚   â”œâ”€â”€ Nuevo_Leon_Financials_2024_Q2_daily.csv
â”‚   â”‚   â”‚   â”œâ”€â”€ Nuevo_Leon_Financials_2024_Q3_daily.csv
â”‚   â”‚   â”‚   â”œâ”€â”€ Nuevo_Leon_Financials_2024_Q4_daily.csv
â”‚   â”‚
â”‚   â”œâ”€â”€ logs/                          # Log storage
â”‚   â”‚   â”œâ”€â”€ .gitkeep                   # Placeholder to ensure directory exists in repo
â”‚   â”‚
â”‚   â”œâ”€â”€ pipelines/                     # ETL orchestrators
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ bulk_presupuesto_pipeline.py  # ETL pipeline for multiple files
â”‚   â”‚   â”œâ”€â”€ bulk_presupuesto_pipeline.yaml  # Config for bulk pipeline
â”‚   â”‚   â”œâ”€â”€ presupuesto_pipeline.py     # ETL pipeline for a single file
â”‚   â”‚   â”œâ”€â”€ presupuesto_pipeline.yaml   # Config for single pipeline
â”‚   â”‚
â”‚   â”œâ”€â”€ etl_project_tests/             # Unit tests for ETL project
â”‚   â”‚   â”œâ”€â”€ assets/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ test_presupuesto_etl.py  # Tests for ETL functions
â”‚   â”‚   â”œâ”€â”€ connectors/
â”‚   â”‚   â”‚   â”œâ”€â”€ test_postgresql.py      # Tests for PostgreSQL connection
â”‚   â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚
â”œâ”€â”€ data/                              # Additional raw data storage
â”‚
â”œâ”€â”€ .env                               # Environment variables (DB credentials)
â”œâ”€â”€ .gitignore                         # Files and folders to ignore in Git
â”œâ”€â”€ Dockerfile                         # Docker setup for containerization
â”œâ”€â”€ README.md                          # Project documentation
â”œâ”€â”€ requirements.txt                    # Python dependencies


## âš™ï¸ **Setup & Installation**

### 1ï¸âƒ£ **Clone the Repository:**
```bash
git clone <repo_url>
cd central
```

### 2ï¸âƒ£ **Create & Activate a Virtual Environment:**
```bash
python -m venv venv
source venv/bin/activate   # On Windows: venv\Scripts\activate
```

### 3ï¸âƒ£ **Install Dependencies:**
```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ **Configure Environment Variables (.env):**
Create a `.env` file in the project root with the following content:

```env
DB_USERNAME=your_db_username
DB_PASSWORD=your_db_password
SERVER_NAME=localhost
DATABASE_NAME=your_database_name
PORT=5432
```

### 5ï¸âƒ£ **Verify PostgreSQL is Running:**
Ensure that PostgreSQL is running locally or remotely and is accessible with the credentials provided in the `.env` file.

---

## ğŸ“‚ **Processing Presupuesto Data**

### âœ… **Run ETL for a Single File:**
To run the ETL process for a single file:

```bash
python central/pipelines/presupuesto_pipeline.py
```

### âœ… **Run ETL for Multiple Files:**
To run the ETL process for all files in the `data/presupuesto_files/` directory:

```bash
python central/pipelines/bulk_presupuesto_pipeline.py
```

The pipeline will process all `.csv` and `.xlsx` files in the directory.

---

## ğŸ“Š **Logging System**

The pipeline uses **Loguru** for advanced logging. Logs include timestamps, log levels, status codes, and descriptive messages.

### âœ… **Log Storage:**
- Logs are stored in the `logs/` directory.
- Each pipeline run creates a **new log file** with a timestamp in its name.

### âœ… **Log Codes:**
| **Code** | **Meaning**                    |
|----------|--------------------------------|
| **100**  | Process started or in progress |
| **200**  | Success/Completion             |
| **400**  | Warning/Recoverable issue      |
| **500**  | Critical Error/Failure         |

---

## ğŸ§® **ETL Process Flow**

1. **Extract** â€” Reads data from CSV/Excel files.
2. **Transform** â€”
    - Cleans and formats the data.
    - Extracts metadata (e.g., year, quarter).
    - Prepares data for insertion into PostgreSQL.
3. **Load** â€”
    - Inserts or upserts data into the PostgreSQL database.
    - Handles conflicts using PostgreSQL's `ON CONFLICT` resolution.

---

## ğŸ’¾ **PostgreSQL Table Structure:**

The financial data is loaded into the `nuevo_leon_financials` table with the following schema:

| **Column**      | **Type** |
|-----------------|----------|
| concept         | String   |
| sublabel        | String   |
| year_quarter    | String   |
| type            | String   |
| amount          | Float    |

---

## ğŸ’¡ **Additional Notes:**

- **Error Handling:**
  - The pipeline logs all errors and skips problematic files during bulk operations.
  - Errors are logged with a **500** status code.

- **Performance:**
  - Log rotation set to **500 MB**.
  - Logs retained for **10 days**.

- **Scalability:**
  - The pipeline is designed to handle large datasets and multiple files.

---

## ğŸ¤ **Contributing:**

1. Fork the repository.
2. Create a new branch (`feature/your-feature`).
3. Commit your changes.
4. Push to the branch.
5. Create a Pull Request.

---

## ğŸ“¬ **Questions & Support:**

If you have any questions or run into issues, please contact the project maintainer or open an issue in the repository.
amoralesb196@gmail.com

Happy ETLing! ğŸš€
